{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7e14da-a951-429e-afe3-711435ce994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.17.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "     ---------------------------------------- 0.0/82.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 41.0/82.7 kB 164.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  81.9/82.7 kB 328.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 82.7/82.7 kB 257.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.2.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kaggle) (3.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.2 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 71.7/78.2 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.2/78.2 kB 730.3 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105798 sha256=00b922d27cc74252d8d7f1daccea20a54bcca7d7a3ede701db7fa781ca403333\n",
      "  Stored in directory: c:\\users\\ramesh.karam\\appdata\\local\\pip\\cache\\wheels\\46\\d2\\26\\84d0a1acdb9c6baccf7d28cf06962ec80529fe1ad938489983\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas numpy\n",
    "!pip install kaggle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3665bb-cde5-4f89-933e-787ced638eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: keras in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: rich in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ramesh.karam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56a4728-8c4e-4d8d-9e09-6b996b173cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b64926-2d3a-4d44-91d7-0eb68f45b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English-French dataset\n",
    "df_french = pd.read_csv('eng_-french.csv') \n",
    "df_french.columns = ['English', 'French']  \n",
    "\n",
    "# Load English-Hindi dataset\n",
    "df_hindi = pd.read_csv('Dataset_English_Hindi.csv')  \n",
    "df_hindi.columns = ['English', 'Hindi']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3ab7a4-5c4e-4bc5-969a-2ba74974ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She told me that she wanted a pet dog.</td>\n",
       "      <td>Elle me dit qu'elle voulait un chien de compag...</td>\n",
       "      <td>उसने मुझसे कहा कि उसे कुत्ता पालने का मन था।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Merci bien.</td>\n",
       "      <td>बहुत बहुत धन्यवाद.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you think she is doing now?</td>\n",
       "      <td>Que pensez-vous qu'elle soit maintenant en tra...</td>\n",
       "      <td>तुम्हारे हिसाब से वह अभी क्या कर रही होगी?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you been abroad?</td>\n",
       "      <td>Avez-vous déjà été à l'étranger ?</td>\n",
       "      <td>आप विदेश गए हुए हैं क्या?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is it? \"It's me.\"</td>\n",
       "      <td>« Qui est là ? » « C'est moi. »</td>\n",
       "      <td>कौन है? \"मैं हूँ\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English  \\\n",
       "0  She told me that she wanted a pet dog.   \n",
       "1                    Thank you very much.   \n",
       "2     What do you think she is doing now?   \n",
       "3                   Have you been abroad?   \n",
       "4                   Who is it? \"It's me.\"   \n",
       "\n",
       "                                              French  \\\n",
       "0  Elle me dit qu'elle voulait un chien de compag...   \n",
       "1                                        Merci bien.   \n",
       "2  Que pensez-vous qu'elle soit maintenant en tra...   \n",
       "3                  Avez-vous déjà été à l'étranger ?   \n",
       "4                    « Qui est là ? » « C'est moi. »   \n",
       "\n",
       "                                          Hindi  \n",
       "0  उसने मुझसे कहा कि उसे कुत्ता पालने का मन था।  \n",
       "1                            बहुत बहुत धन्यवाद.  \n",
       "2    तुम्हारे हिसाब से वह अभी क्या कर रही होगी?  \n",
       "3                     आप विदेश गए हुए हैं क्या?  \n",
       "4                             कौन है? \"मैं हूँ\"  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine datasets\n",
    "df_combined = pd.merge(df_french, df_hindi, on='English', how='outer')\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_combined.dropna(inplace=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_combined = df_combined.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check the combined dataset\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab542aed-ad7d-4ab0-a4be-2674bbcec42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2348,) (588,) (2348,) (588,) (2348,) (588,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_combined['English']\n",
    "y_french = df_combined['French']\n",
    "y_hindi = df_combined['Hindi']\n",
    "\n",
    "X_train, X_test, y_train_french, y_test_french, y_train_hindi, y_test_hindi = train_test_split(\n",
    "    X, y_french, y_hindi, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the data\n",
    "print(X_train.shape, X_test.shape, y_train_french.shape, y_test_french.shape, y_train_hindi.shape, y_test_hindi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa668be-c617-45f0-95b4-b4cc936805a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2348, 16) (588, 16)\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer_en = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_en.fit_on_texts(X_train)\n",
    "\n",
    "tokenizer_fr = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_fr.fit_on_texts(y_train_french)\n",
    "\n",
    "tokenizer_hi = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_hi.fit_on_texts(y_train_hindi)\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train_seq = tokenizer_en.texts_to_sequences(X_train)\n",
    "y_train_fr_seq = tokenizer_fr.texts_to_sequences(y_train_french)\n",
    "y_train_hi_seq = tokenizer_hi.texts_to_sequences(y_train_hindi)\n",
    "\n",
    "X_test_seq = tokenizer_en.texts_to_sequences(X_test)\n",
    "y_test_fr_seq = tokenizer_fr.texts_to_sequences(y_test_french)\n",
    "y_test_hi_seq = tokenizer_hi.texts_to_sequences(y_test_hindi)\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max([len(seq) for seq in X_train_seq])\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Check shapes of padded sequences\n",
    "print(X_train_pad.shape, X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a44894-b163-4ab2-b271-dc9270f4f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "vocab_size_en = len(tokenizer_en.word_index) + 1\n",
    "vocab_size_fr = len(tokenizer_fr.word_index) + 1\n",
    "vocab_size_hi = len(tokenizer_hi.word_index) + 1\n",
    "embedding_dim = 128\n",
    "\n",
    "# Build the model\n",
    "def create_model(vocab_size, max_length):\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "        layers.LSTM(128, return_sequences=False),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create models for French and Hindi translations\n",
    "model_fr = create_model(vocab_size_fr, max_length)\n",
    "model_hi = create_model(vocab_size_hi, max_length)\n",
    "\n",
    "# Compile the models\n",
    "model_fr.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_hi.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e3aaf4-b552-4115-8a2d-5e18e9b6d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.1063 - loss: 6.5458 - val_accuracy: 0.1170 - val_loss: 4.7863\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1336 - loss: 4.4046 - val_accuracy: 0.1000 - val_loss: 4.7707\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1152 - loss: 4.2799 - val_accuracy: 0.1170 - val_loss: 4.8033\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1258 - loss: 4.3356 - val_accuracy: 0.1170 - val_loss: 4.8452\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1380 - loss: 4.2508 - val_accuracy: 0.1170 - val_loss: 4.8537\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1302 - loss: 4.3407 - val_accuracy: 0.1170 - val_loss: 4.8522\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1124 - loss: 4.3022 - val_accuracy: 0.1170 - val_loss: 4.8878\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1340 - loss: 4.2848 - val_accuracy: 0.1170 - val_loss: 4.9004\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1395 - loss: 4.2738 - val_accuracy: 0.1170 - val_loss: 4.7915\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.1227 - loss: 4.1366 - val_accuracy: 0.1106 - val_loss: 4.5801\n",
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.0792 - loss: 6.6260 - val_accuracy: 0.0851 - val_loss: 4.8538\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0749 - loss: 4.5697 - val_accuracy: 0.0553 - val_loss: 4.8244\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.0739 - loss: 4.5009 - val_accuracy: 0.0851 - val_loss: 4.8389\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0880 - loss: 4.4681 - val_accuracy: 0.0851 - val_loss: 4.8919\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0778 - loss: 4.4853 - val_accuracy: 0.0851 - val_loss: 4.9154\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0944 - loss: 4.4629 - val_accuracy: 0.0830 - val_loss: 4.8949\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0786 - loss: 4.4737 - val_accuracy: 0.0851 - val_loss: 4.9432\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1015 - loss: 4.4886 - val_accuracy: 0.0553 - val_loss: 4.6209\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0789 - loss: 4.3051 - val_accuracy: 0.1532 - val_loss: 4.4461\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1317 - loss: 3.9762 - val_accuracy: 0.1638 - val_loss: 4.3023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x267d15b89e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare y for training (only use the first token of the target sequence)\n",
    "y_train_fr = np.array([seq[0] for seq in y_train_fr_seq])\n",
    "y_train_hi = np.array([seq[0] for seq in y_train_hi_seq])\n",
    "\n",
    "# Train the French translation model\n",
    "model_fr.fit(X_train_pad, y_train_fr, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Train the Hindi translation model\n",
    "model_hi.fit(X_train_pad, y_train_hi, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29cc664-8b40-4126-b164-4190a8a746a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained models\n",
    "model_fr.save('english_to_french_model.keras')\n",
    "model_hi.save('english_to_hindi_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efcfcf0-b415-4bf7-a19c-e30e8dfd7ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Translation Model Accuracy: 0.11224489659070969\n",
      "Hindi Translation Model Accuracy: 0.15986394882202148\n"
     ]
    }
   ],
   "source": [
    "# Convert the target sequences to numpy arrays for evaluation\n",
    "y_test_fr_array = np.array([seq[0] if len(seq) > 0 else 0 for seq in y_test_fr_seq])\n",
    "y_test_hi_array = np.array([seq[0] if len(seq) > 0 else 0 for seq in y_test_hi_seq])\n",
    "\n",
    "# Evaluate the models\n",
    "fr_loss, fr_acc = model_fr.evaluate(X_test_pad, y_test_fr_array, verbose=0)\n",
    "hi_loss, hi_acc = model_hi.evaluate(X_test_pad, y_test_hi_array, verbose=0)\n",
    "\n",
    "print(f'French Translation Model Accuracy: {fr_acc}')\n",
    "print(f'Hindi Translation Model Accuracy: {hi_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd119bc1-b88b-419e-9df4-9cb8dcb5517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_pad shape: (588, 16)\n",
      "y_test_fr_array shape: (588,)\n",
      "y_test_hi_array shape: (588,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_test_pad shape: {X_test_pad.shape}')\n",
    "print(f'y_test_fr_array shape: {y_test_fr_array.shape}')\n",
    "print(f'y_test_hi_array shape: {y_test_hi_array.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5bd5b5f-9eb2-460f-921d-ddbeab543af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "French: merci, Hindi: तुम\n"
     ]
    }
   ],
   "source": [
    "def translate(text):\n",
    "    # Tokenize and pad the input\n",
    "    input_seq = tokenizer_en.texts_to_sequences([text])\n",
    "    input_pad = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Predict French\n",
    "    fr_pred = model_fr.predict(input_pad)\n",
    "    fr_word_index = np.argmax(fr_pred, axis=-1)\n",
    "    fr_word = tokenizer_fr.index_word[fr_word_index[0]]\n",
    "\n",
    "    # Predict Hindi\n",
    "    hi_pred = model_hi.predict(input_pad)\n",
    "    hi_word_index = np.argmax(hi_pred, axis=-1)\n",
    "    hi_word = tokenizer_hi.index_word[hi_word_index[0]]\n",
    "\n",
    "    return fr_word, hi_word\n",
    "\n",
    "# Example usage\n",
    "english_word = \"example\"\n",
    "french_translation, hindi_translation = translate(english_word)\n",
    "print(f\"French: {french_translation}, Hindi: {hindi_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02a0a6-c891-4473-af94-0a123d430df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
